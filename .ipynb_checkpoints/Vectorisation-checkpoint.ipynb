{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-whale",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/fr/thumb/e/ed/Logo_Universit%C3%A9_du_Maine.svg/1280px-Logo_Universit%C3%A9_du_Maine.svg.png' width=\"300\" height=\"500\">\n",
    "<br>\n",
    "<div style=\"border: solid 3px #000;\">\n",
    "    <h1 style=\"text-align: center; color:#000; font-family:Georgia; font-size:26px;\">Infrastructures pour l'IA</h1>\n",
    "    <p style='text-align: center;'>Master Informatique 1</p>\n",
    "    <p style='text-align: center;'>Anhony Larcher</p>\n",
    "</div>\n",
    "\n",
    "Cette session est organisée comme un challenge:\n",
    "* Vous optimiserez un code afin d'effectuer un calcul le plus rapidement possible\n",
    "* le résultat sera utilisée dans le TP numéro 6 pour faire du calcul parallélisé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f937f-8bd2-40e8-8ed5-1d35c51837b6",
   "metadata": {},
   "source": [
    "# Implémenter le calcul suivant et optimisez le au mieux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170d483",
   "metadata": {},
   "source": [
    "Il s'agit d'accumuler les statistiques d'ordre 0 et d'ordre 1 sur un mélange de Gaussiennes. Vous trouverez sur Umtice une archive zip contenant un objet Mixture et des paramètres acoustiques de type MFCC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3f254-3206-4924-985d-7ad095b801e7",
   "metadata": {},
   "source": [
    "Chaque distribution de la mixture a pour densité de probabilité:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446f09b-e1b0-48cf-be6f-c6ab532bd8ac",
   "metadata": {},
   "source": [
    "Et la densité de probabilité du mélange de Gaussienne est \n",
    "$$p(x|\\lambda) = \\Sigma_{i=1}^{M}w_ip_i(x)$$\n",
    "\n",
    "où $$\\Sigma_{i=1}^{M}w_i = 1$$\n",
    "\n",
    "et \n",
    "\n",
    "$$p_i(x) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} e^{-(\\frac{1}{2}(x - \\mu)^T\\Sigma_i^{-1}(x-\\mu))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-weather",
   "metadata": {},
   "source": [
    "Nous souhaiton ici calculer pour chaque trame $x_t$\n",
    "\n",
    "$$P(i|x_t) = \\frac{w_ip_i(x_t)}{\\Sigma_{j=1}^M w_j p_j(x(t))}$$\n",
    "\n",
    "Pour ensuite calculer les statistiques d'ordre 0 pour chaque gaussienne $i$:\n",
    "\n",
    "$$n_i = \\Sigma_{t=1}^{T}P(i|x_t)$$\n",
    "\n",
    "Les statistiques d'ordre 1:\n",
    "\n",
    "$$E_i(x) = \\frac{1}{n_i} \\Sigma_{t=1}^{T}P(i|x_t)x_t$$\n",
    "\n",
    "Et les statistiques d'ordre 2:\n",
    "\n",
    "$$E_i(x^2) = \\frac{1}{n_i} \\Sigma_{t=1}^{T}P(i|x_t)x_t^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03927e-a2e2-435b-afed-195b98682349",
   "metadata": {},
   "source": [
    "Les données sont disponibles ici:\n",
    "\n",
    "    https://umbox.univ-lemans.fr/index.php/s/CiP47cfw8NBMM5J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094eb943",
   "metadata": {},
   "source": [
    "## 1.1) Initialisez l'accumulateur de statistiques\n",
    "\n",
    "Le fichier ``mixture.py``contient le code d'une classe Mixtuyre qui sera utilisé dans ce TP. Ce code se trouve également dans la cellule ci-dessous pour travailler dans le notebook. Une fois la cellule ci-dessous complétée vous pourrez recopier le code dans le fichier ``mixture.py``afin d'avoir une version propre du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4099388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Mixture(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize an empty Mixture object\n",
    "        \"\"\"\n",
    "        self.w = numpy.array([])\n",
    "        self.mu = numpy.array([])\n",
    "        self.invcov = numpy.array([])\n",
    "        self.cst = numpy.array([])\n",
    "        self.det = numpy.array([])\n",
    "        self.D = 0 \n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Serialize a Mixture object to text\n",
    "        \"\"\"\n",
    "        return f'w = {self.w.shape}{self.w}\\nmu = {self.mu.shape}{self.mu}\\ninvcov = {self.invcov.shape}{self.invcov}\\ncst = {self.cst.shape}{self.cst}\\ndet = {self.det.shape}{self.det}'\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, filename):\n",
    "        \"\"\"\n",
    "        Read a Mixture object stored in Pickle format on disk\n",
    "        :param filename: the name of the file to read from\n",
    "        :return: a Mixture object\n",
    "        \"\"\"\n",
    "        with open(filename, 'rb') as fh:\n",
    "            mixture = pickle.load(fh)\n",
    "            return mixture\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save a Mixture object to disk in Pickle format\n",
    "        :param filename: the name of the file to write to\n",
    "        \"\"\"\n",
    "        with open(filename, 'wb') as fh:\n",
    "            pickle.dump(self, fh)\n",
    "\n",
    "    def loadPresets(self):\n",
    "        self.mu = numpy.load(\"mu.npy\")\n",
    "        self.w  = numpy.load(\"w.npy\")\n",
    "        self.invcov = numpy.load(\"invcov.npy\")\n",
    "        self.D = self.mu.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e53141",
   "metadata": {},
   "source": [
    "## Analyse des formules\n",
    "\n",
    "On remarque d'abord que certains éléments dépendent des données, et plus particulièrement de chaque vecteur de donnée, mais également de chaque distribution de la mixture.\n",
    "\n",
    "Nous verrons donc apparaitre 2 boucles principales:\n",
    "* une sur les données\n",
    "* une sur les distributions\n",
    "\n",
    "Pour simplifier le calcul nous devons donc séparer ce qui est indépendant de ces boucles afin de ne pas le recalculer plusieurs fois.\n",
    "\n",
    "Ré-écrivez $$p_i(x)$$ en séparant ces termes.\n",
    "\n",
    "$$p_i(x) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} e^{-(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i))}$$\n",
    "\n",
    "On trouve d'abord un terme qui dépend de chaque mixture: leur déterminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17f0d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w = (64,)[0.02844993 0.02996182 0.01964361 0.01862646 0.01975147 0.01309353\n",
       " 0.02502924 0.00291    0.01475639 0.02127246 0.01021711 0.02329464\n",
       " 0.01555235 0.01373919 0.02967175 0.02548854 0.00761562 0.0012263\n",
       " 0.02935303 0.00414223 0.02463111 0.01124941 0.00019797 0.02672781\n",
       " 0.00313988 0.01912293 0.01354564 0.02600196 0.01817349 0.00568998\n",
       " 0.01298897 0.00471729 0.00852454 0.00741755 0.02375921 0.00274827\n",
       " 0.02174288 0.02735786 0.0137794  0.01746969 0.02331403 0.01422279\n",
       " 0.02061638 0.02262861 0.0028007  0.01700206 0.00393644 0.02978915\n",
       " 0.02621173 0.0114424  0.00437376 0.00385283 0.01537251 0.02239445\n",
       " 0.01575902 0.00360997 0.01605286 0.01875063 0.02570423 0.01702322\n",
       " 0.00605788 0.02080033 0.01238033 0.00312217]\n",
       "mu = (64, 39)[[ 1.47965785  1.17734999 -0.2631497  ... -0.37937336 -1.32008917\n",
       "   1.15598038]\n",
       " [ 1.36076938  2.80015315  0.74567541 ...  0.18342471  1.49951375\n",
       "   0.2304865 ]\n",
       " [ 0.05852055 -0.21735994  1.3437309  ...  1.05283074 -1.00595318\n",
       "   0.15418253]\n",
       " ...\n",
       " [-1.01092256 -0.52275431 -0.23223543 ...  0.37988891 -2.05773478\n",
       "  -0.05094653]\n",
       " [ 0.59150904 -0.19911688  0.50387813 ... -0.86531547  0.30299783\n",
       "   0.49722785]\n",
       " [ 1.11082188  0.00535697 -0.13129625 ... -1.70540661 -1.29952406\n",
       "   0.08154551]]\n",
       "invcov = (64, 39)[[0.57644626 0.68576746 0.62941113 ... 0.75738399 0.57559068 0.66871915]\n",
       " [0.80763037 0.76329883 0.69521484 ... 0.87043643 0.69031538 0.74854336]\n",
       " [0.81601115 0.76350196 0.72462563 ... 0.81519951 0.81604256 0.86340996]\n",
       " ...\n",
       " [0.72634523 0.59532771 0.71438645 ... 0.72438607 0.7639669  0.77606345]\n",
       " [0.71545848 0.84455897 0.84399906 ... 0.63912259 0.78547948 0.91511047]\n",
       " [0.59150909 0.61340457 0.68649622 ... 0.61529548 0.71058816 0.57820938]]\n",
       "cst = (0,)[]\n",
       "det = (0,)[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Il faut donc calculer ce déterminant une seule fois:\n",
    "# Le déterminant d'une matrice diagonale est le produit de ses termes diagonaux.\n",
    "# Les covariances inverses étant stockées par ligne dans self.invcov nous calculons\n",
    "mixture = Mixture()\n",
    "mixture.loadPresets()\n",
    "mixture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a673e834",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant calculer le premier terme pour chaque distribution:\n",
    "    \n",
    "$$ \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99a3e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.72730792e-20 8.70832078e-19 4.26940727e-18 8.60841752e-20\n",
      " 2.73596235e-19 1.24578688e-19 3.94124146e-20 6.29192526e-19\n",
      " 9.53534477e-19 2.92141068e-20 1.30243154e-18 1.26007075e-18\n",
      " 2.65708834e-19 9.97583467e-20 6.05072648e-18 7.14329984e-20\n",
      " 9.79911377e-18 3.58467057e-18 1.61381237e-18 5.41968623e-19\n",
      " 4.34401698e-20 1.42616421e-19 6.88889365e-20 1.44117697e-18\n",
      " 5.78937861e-20 3.87487599e-18 1.40489448e-18 3.60891615e-19\n",
      " 1.62497110e-19 4.00764671e-19 5.61514015e-19 6.92236910e-19\n",
      " 7.69899030e-18 8.52626037e-20 4.53888757e-20 3.15750969e-18\n",
      " 1.90347497e-18 3.68987041e-18 1.32845185e-19 6.76144105e-20\n",
      " 2.92465189e-20 9.57178321e-19 9.91891936e-19 8.16038209e-20\n",
      " 1.91971962e-18 7.70949367e-20 2.93829401e-18 1.10194597e-18\n",
      " 2.19909318e-19 2.93245192e-19 3.60687542e-20 2.32996404e-20\n",
      " 8.83463191e-19 3.06892947e-19 1.02270074e-19 1.06758988e-19\n",
      " 6.13597319e-20 7.12555038e-20 1.35843002e-19 3.18030013e-18\n",
      " 5.01664791e-18 4.37035422e-19 2.79311598e-18 3.72929214e-20]\n",
      "\n",
      "[1.04002334e+12 1.17205849e+13 5.74622267e+13 1.15861244e+12\n",
      " 3.68234931e+12 1.67671256e+12 5.30454219e+11 8.46834262e+12\n",
      " 1.28336818e+13 3.93194540e+11 1.75295098e+13 1.69593731e+13\n",
      " 3.57619226e+12 1.34265400e+12 8.14371164e+13 9.61421314e+11\n",
      " 1.31886902e+14 4.82463115e+13 2.17204044e+13 7.29439051e+12\n",
      " 5.84664035e+11 1.91948357e+12 9.27180622e+11 1.93968934e+13\n",
      " 7.79196186e+11 5.21522048e+13 1.89085651e+13 4.85726343e+12\n",
      " 2.18705905e+12 5.39391746e+12 7.55745320e+12 9.31686104e+12\n",
      " 1.03621205e+14 1.14755486e+12 6.10891793e+11 4.24971258e+13\n",
      " 2.56189920e+13 4.96622029e+13 1.78797187e+12 9.10026694e+11\n",
      " 3.93630777e+11 1.28827245e+13 1.33499373e+13 1.09831107e+12\n",
      " 2.58376296e+13 1.03762571e+12 3.95466878e+13 1.48311617e+13\n",
      " 2.95977364e+12 3.94680588e+12 4.85451679e+11 3.13591357e+11\n",
      " 1.18905878e+13 4.13049188e+12 1.37645949e+12 1.43687607e+12\n",
      " 8.25844573e+11 9.59032403e+11 1.82831970e+12 4.28038638e+13\n",
      " 6.75193864e+13 5.88208782e+12 3.75927274e+13 5.01927824e+11]\n",
      "\n",
      "Naive implementation took: 2559.0us and Numpy implementation took: 473.6us\n",
      " Hence, Numpy is 5.403293918918919 times faster.\n"
     ]
    }
   ],
   "source": [
    "# D étant constant, on voit d'ores et déjà que (2Pi)^(D/2) est une constante également.\n",
    "# Calculons le:\n",
    "cst_2pi = numpy.power((2.0*numpy.pi), (mixture.D/2.0))\n",
    "\n",
    "# Ensuite, le grand Sigma dans notre équation, c'est la matrice de covariance.\n",
    "# Comme on l'a expliqué en TD, pour simplifier les calculs on ne prend qu'une matrice diagonale.\n",
    "# Ce qui est chouette c'est que le determinant d'une matrice diagonale est juste le produit de ses termes diagonaux.\n",
    "#\n",
    "# Seul petit détail, on nous a donné l'inverse de la covariance. Il faudra donc la recalculer.\n",
    "# C'est pas bien gênant, on fait juste 1/v pour chaque valeur.\n",
    "#\n",
    "# Enfin, n'oublions la racine carré sur le determinant de la covariance.\n",
    "#\n",
    "# Manque plus qu'inverser tout ça et ce sera bon.\n",
    "\n",
    "#TODO: faire un truc en pure python pour expliciter les calculs\n",
    "import math\n",
    "import time\n",
    "\n",
    "start1 = time.perf_counter_ns()\n",
    "size = mixture.invcov.shape[0]\n",
    "prods = numpy.array([1.0] * size)\n",
    "for i in range(size):\n",
    "    # Multiply each value of the diagonal as we want the determinant\n",
    "    for val in mixture.invcov[i]:\n",
    "        prods[i] *= val\n",
    "\n",
    "    # Inverse that as we are given the inverse of the covariant\n",
    "    prods[i] = 1.0 / prods[i]\n",
    "\n",
    "    # Take it's square root\n",
    "    prods[i] = math.sqrt(prods[i])\n",
    "\n",
    "    # Multiply that by the constant with Pi\n",
    "    prods[i] *= cst_2pi\n",
    "\n",
    "    # And then inverse that once again as per the formula\n",
    "    prods[i] = 1.0 / prods[i]\n",
    "end1 = time.perf_counter_ns()\n",
    "res_naive = end1-start1\n",
    "\n",
    "start = time.perf_counter_ns()\n",
    "prods_npy = 1.0 / ( cst_2pi * numpy.sqrt( 1.0 / numpy.prod(mixture.invcov, axis=1) ))\n",
    "end = time.perf_counter_ns()\n",
    "res_numpy = end-start\n",
    "print(truc)\n",
    "\n",
    "print(f\"\\nNaive implementation took: {res_naive/1000}us and Numpy implementation took: {res_numpy/1000}us\\n\",\n",
    "      f\"Hence, Numpy is {res_naive/res_numpy} times faster.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c145a9",
   "metadata": {},
   "source": [
    "Regardons maintenant le terme contenu dans l'exponentielle:\n",
    "\n",
    "$$ -(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)) $$ \n",
    "\n",
    "Tout ce terme dépend des distributions, une partie seulement dépend des données.\n",
    "\n",
    "$$ -(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)) = -\\frac{1}{2} ( x^T\\Sigma_i^{-1}x + \\mu_i^T\\Sigma_i^{-1}\\mu_i - x^T\\Sigma_i^{-1}\\mu_i - \\mu_i^T\\Sigma_i^{-1}x ) $$ \n",
    "\n",
    "Calculez chacun de ces termes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cade4",
   "metadata": {},
   "source": [
    "Analyse du terme independant des données:\n",
    "\n",
    "$$ \\mu_i^T\\Sigma_i^{-1}\\mu_i $$\n",
    "\n",
    "$$ \\mu_i^T$$ est de dimension (1, 39) $$\\Sigma_i$$ est de dimension (39, 39)\n",
    "\n",
    "Donc $$ \\mu_i^T\\Sigma_i^{-1}\\mu_i $$ est de dimension (1,)\n",
    "\n",
    "Pareil pour le terme $$ x^T\\Sigma_i^{-1}x = \\sum_{n=1}^{39}{x^2 \\sigma_n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En pratique, comme la matruice de covariance est diagonale, nous n'avons pas besoin de calculer un vrai produit matriciel\n",
    "# Écrivez la valeur du premier terme de \\mu_i \\Sigma^{-1}_i et tirez partie de cette expression pour simplifier\n",
    "# le calcul de ce terme\n",
    "\n",
    "# self.mu est de dimension 64x39\n",
    "# self.invcov est de dimension 64x39\n",
    "# numpy.square(self.mu) * self.invcov) est de dimension 64x39\n",
    "# numpy.square(self.mu) * self.invcov).sum(1) est de dimension 64 \n",
    "# A est de dimension 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738780d-c5ce-4136-a2e3-9a9911029daa",
   "metadata": {},
   "source": [
    "## 1.2) Écrivez une fonction compute_lpp \n",
    "\n",
    "Cette méthode de la class **Mixture** va calculer les log posterior probabilités $$\\log{p_i(x)}$$ d'un ensemble de vecteurs sur ce mélange de Gaussienne à matrices de covariances diagonales\n",
    "\n",
    "Pour acumuler les statistiques, vous allez créer un objet mixture que vous appelerez **accum**.\n",
    "\n",
    "* Cette méthode prend en paramètres une matrice de coefficients cepstraux de dimension N x F où N est le nombre de vecteurs (variable selon les fichiers) et F est la dimension des vecteurs (39 dans notre cas)\n",
    "* En premier lieu, pensez à extraire des boucles tous les termes qui ne dépendent pas des données\n",
    "* Cette méthode renvoie les $$n_i$$ (donc un vecteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73558128-8817-4016-aa2d-f8559ad436ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "X = numpy.load(\"features_1.npy\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61a954-76a6-4ecf-b6b1-61ee35c4d235",
   "metadata": {},
   "source": [
    "## 1.3) Utilisez la fonction **sum_log_probabilities**\n",
    "* Que fait cette fonction qui vous est donnée?\n",
    "* Pourquoi l'utilise-t'on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b29bd63-76a6-4290-81b2-f6ae7f73693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_log_probabilities(lp):\n",
    "    \"\"\"Sum log probabilities in a secure manner to avoid extreme values\n",
    "\n",
    "    :param lp: numpy array of log-probabilities to sum\n",
    "    \"\"\"\n",
    "    pp_max = numpy.max(lp, axis=1)\n",
    "    log_lk = pp_max + numpy.log(numpy.sum(numpy.exp((lp.transpose() - pp_max).T), axis=1))\n",
    "    ind = ~numpy.isfinite(pp_max)\n",
    "    if sum(ind) != 0:\n",
    "        log_lk[ind] = pp_max[ind]\n",
    "    pp = numpy.exp((lp.transpose() - log_lk).transpose())\n",
    "    llk = log_lk.sum()\n",
    "    return pp, llk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1ee10-f7d7-4be1-9e0a-762be74bb52d",
   "metadata": {},
   "source": [
    "## 1.4) Bouclez sur les fichiers de paramètres pour accumuler les statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c44723-f60f-4371-b18d-6f2d4c98dbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
