{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-whale",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/fr/thumb/e/ed/Logo_Universit%C3%A9_du_Maine.svg/1280px-Logo_Universit%C3%A9_du_Maine.svg.png' width=\"300\" height=\"500\">\n",
    "<br>\n",
    "<div style=\"border: solid 3px #000;\">\n",
    "    <h1 style=\"text-align: center; color:#000; font-family:Georgia; font-size:26px;\">Infrastructures pour l'IA</h1>\n",
    "    <p style='text-align: center;'>Master Informatique 1</p>\n",
    "    <p style='text-align: center;'>Anhony Larcher</p>\n",
    "</div>\n",
    "\n",
    "Cette session est organisée comme un challenge:\n",
    "* Vous optimiserez un code afin d'effectuer un calcul le plus rapidement possible\n",
    "* le résultat sera utilisée dans le TP numéro 6 pour faire du calcul parallélisé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f937f-8bd2-40e8-8ed5-1d35c51837b6",
   "metadata": {},
   "source": [
    "# Implémenter le calcul suivant et optimisez le au mieux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170d483",
   "metadata": {},
   "source": [
    "Il s'agit d'accumuler les statistiques d'ordre 0 et d'ordre 1 sur un mélange de Gaussiennes. Vous trouverez sur Umtice une archive zip contenant un objet Mixture et des paramètres acoustiques de type MFCC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3f254-3206-4924-985d-7ad095b801e7",
   "metadata": {},
   "source": "Chaque distribution de la mixture a pour densité de probabilité:"
  },
  {
   "cell_type": "markdown",
   "id": "5446f09b-e1b0-48cf-be6f-c6ab532bd8ac",
   "metadata": {},
   "source": [
    "Et la densité de probabilité du mélange de Gaussienne est \n",
    "$$p(x|\\lambda) = \\Sigma_{i=1}^{M}w_ip_i(x)$$\n",
    "\n",
    "où $$\\Sigma_{i=1}^{M}w_i = 1$$\n",
    "\n",
    "et \n",
    "\n",
    "$$p_i(x) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} e^{-(\\frac{1}{2}(x - \\mu)^T\\Sigma_i^{-1}(x-\\mu))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-weather",
   "metadata": {},
   "source": [
    "Nous souhaiton ici calculer pour chaque trame $x_t$\n",
    "\n",
    "$$P(i|x_t) = \\frac{w_ip_i(x_t)}{\\Sigma_{j=1}^M w_j p_j(x_t)}$$\n",
    "\n",
    "Pour ensuite calculer les statistiques d'ordre 0 pour chaque gaussienne $i$:\n",
    "\n",
    "$$n_i = \\Sigma_{t=1}^{T}P(i|x_t)$$\n",
    "\n",
    "Les statistiques d'ordre 1:\n",
    "\n",
    "$$E_i(x) = \\frac{1}{n_i} \\Sigma_{t=1}^{T}P(i|x_t)x_t$$\n",
    "\n",
    "Et les statistiques d'ordre 2:\n",
    "\n",
    "$$E_i(x^2) = \\frac{1}{n_i} \\Sigma_{t=1}^{T}P(i|x_t)x_t^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03927e-a2e2-435b-afed-195b98682349",
   "metadata": {},
   "source": [
    "Les données sont disponibles ici:\n",
    "\n",
    "    https://umbox.univ-lemans.fr/index.php/s/CiP47cfw8NBMM5J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094eb943",
   "metadata": {},
   "source": [
    "## 1.1) Initialisez l'accumulateur de statistiques\n",
    "\n",
    "Le fichier ``mixture.py``contient le code d'une classe Mixtuyre qui sera utilisé dans ce TP. Ce code se trouve également dans la cellule ci-dessous pour travailler dans le notebook. Une fois la cellule ci-dessous complétée vous pourrez recopier le code dans le fichier ``mixture.py``afin d'avoir une version propre du code."
   ]
  },
  {
   "cell_type": "code",
   "id": "4099388c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:50:49.525740Z",
     "start_time": "2024-09-12T13:50:49.335954Z"
    }
   },
   "source": [
    "import numpy\n",
    "import pickle\n",
    "\n",
    "class Mixture(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize an empty Mixture object\n",
    "        \"\"\"\n",
    "        self.w = numpy.array([])\n",
    "        self.mu = numpy.array([])\n",
    "        self.invcov = numpy.array([])\n",
    "        self.cst = numpy.array([])\n",
    "        self.det = numpy.array([])\n",
    "        self.D = 0 \n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Serialize a Mixture object to text\n",
    "        \"\"\"\n",
    "        return f'w = {self.w.shape}{self.w}\\nmu = {self.mu.shape}{self.mu}\\ninvcov = {self.invcov.shape}{self.invcov}\\ncst = {self.cst.shape}{self.cst}\\ndet = {self.det.shape}{self.det}'\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, filename):\n",
    "        \"\"\"\n",
    "        Read a Mixture object stored in Pickle format on disk\n",
    "        :param filename: the name of the file to read from\n",
    "        :return: a Mixture object\n",
    "        \"\"\"\n",
    "        with open(filename, 'rb') as fh:\n",
    "            mixture = pickle.load(fh)\n",
    "            return mixture\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save a Mixture object to disk in Pickle format\n",
    "        :param filename: the name of the file to write to\n",
    "        \"\"\"\n",
    "        with open(filename, 'wb') as fh:\n",
    "            pickle.dump(self, fh)\n",
    "\n",
    "    def loadPresets(self):\n",
    "        self.mu = numpy.load(\"mu.npy\")\n",
    "        self.w  = numpy.load(\"w.npy\")\n",
    "        self.invcov = numpy.load(\"invcov.npy\")\n",
    "        self.D = self.mu.shape[1]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "83e53141",
   "metadata": {},
   "source": [
    "## Analyse des formules\n",
    "\n",
    "On remarque d'abord que certains éléments dépendent des données, et plus particulièrement de chaque vecteur de donnée, mais également de chaque distribution de la mixture.\n",
    "\n",
    "Nous verrons donc apparaitre 2 boucles principales:\n",
    "* une sur les données\n",
    "* une sur les distributions\n",
    "\n",
    "Pour simplifier le calcul nous devons donc séparer ce qui est indépendant de ces boucles afin de ne pas le recalculer plusieurs fois.\n",
    "\n",
    "Ré-écrivez $$p_i(x)$$ en séparant ces termes.\n",
    "\n",
    "$$p_i(x) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} e^{-(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i))}$$\n",
    "\n",
    "On trouve d'abord un terme qui dépend de chaque mixture: leur déterminant"
   ]
  },
  {
   "cell_type": "code",
   "id": "f17f0d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:08:10.764192Z",
     "start_time": "2024-09-12T14:08:10.747897Z"
    }
   },
   "source": [
    "# Il faut donc calculer ce déterminant une seule fois:\n",
    "# Les covariances inverses étant stockées par ligne dans self.invcov nous calculons simplement le produit de chaque ligne.\n",
    "# Le grand Sigma dans notre équation, c'est la matrice de covariance.\n",
    "# Comme on l'a expliqué en TD, pour simplifier les calculs on ne prend qu'une matrice diagonale, car ça va plus vite à calculer\n",
    "# Ce qui est chouette c'est que le determinant d'une matrice diagonale est juste le produit de ses termes diagonaux.\n",
    "# Seul petit détail, on nous a donné l'inverse de la covariance. Il faudra donc la recalculer.\n",
    "# C'est pas bien gênant, on fait juste 1/v pour chaque valeur, car dans le cas d'une matrice diagonale on peut calculer son inverse comme ça.\n",
    "#\n",
    "# Just a little note, in the following code cells of this notebook, I am not going to use the mixture object above, but rather do the code inline and adapt it in the Mixture class.\n",
    "\n",
    "from time import perf_counter_ns as perf\n",
    "\n",
    "invcov = numpy.load(\"invcov.npy\")\n",
    "\n",
    "# With loops and no numpy\n",
    "start = perf()\n",
    "det = []\n",
    "for line in invcov:\n",
    "    det.append(1)\n",
    "    for val in line:\n",
    "        det[-1] *= val\n",
    "    det[-1] = 1 / det[-1]\n",
    "end = perf()\n",
    "naive_imple = end-start\n",
    "        \n",
    "start = perf()\n",
    "det = 1.0 / numpy.prod(invcov, axis=1)\n",
    "end = perf()\n",
    "numpy_imple = end-start\n",
    "\n",
    "print(f\"Naive implementation took {naive_imple/1000} microseconds\\n\"\n",
    "      f\"Numpy implementation took {numpy_imple/1000} microseconds\\n\"\n",
    "      f\"So, numpy here is {naive_imple/numpy_imple:.2f} times faster\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive implementation took 1712.3 nanoseconds\n",
      "Numpy implementation took 211.3 nanoseconds\n",
      "So, numpy here is 8.10 times faster\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "a673e834",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant calculer le premier terme pour chaque distribution:\n",
    "    \n",
    "$$ \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} $$ "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T14:09:06.248997Z",
     "start_time": "2024-09-12T14:09:06.236774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# D étant constant, on voit d'ores et déjà que (2Pi)^(D/2) est une constante également. Le déterminant de la matrice de covariance ne dépend pas des donnés, on peut donc calculer cette fraction en amont, une seule fois pour toutes les données puisqu'elles n'influent pas dans le calcul ici.\n",
    "# Enfin, n'oublions la racine carré sur le determinant de la covariance.\n",
    "# Manque plus qu'inverser tout ça et ce sera bon.\n",
    "\n",
    "import math\n",
    "\n",
    "D = invcov.shape[1]\n",
    "\n",
    "### Pure python implementation ###\n",
    "start = perf()\n",
    "cst = []\n",
    "for line in det:\n",
    "    cst.append( 1.0 / (2.0 * math.pi)**(D/2.0) * (math.sqrt(line)) )\n",
    "end = perf()\n",
    "naive_imple = end-start\n",
    "\n",
    "### Numpy implementation ###\n",
    "start = perf()\n",
    "cst = 1.0 / ( numpy.power(2.0 * numpy.pi, D/2.0) * numpy.sqrt( det ))\n",
    "end = perf()\n",
    "numpy_imple = end-start\n",
    "\n",
    "print(f\"Naive implementation took {naive_imple/1000} microseconds\\n\"\n",
    "      f\"Numpy implementation took {numpy_imple/1000} microseconds\\n\"\n",
    "      f\"So, numpy here is {naive_imple/numpy_imple:.2f} times faster\")\n"
   ],
   "id": "99a3e19e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive implementation took 332.8 microseconds\n",
      "Numpy implementation took 256.2 microseconds\n",
      "So, numpy here is 1.30 times faster\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "a6c145a9",
   "metadata": {},
   "source": [
    "Regardons maintenant le terme contenu dans l'exponentielle:\n",
    "\n",
    "$$ -(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)) $$ \n",
    "\n",
    "Tout ce terme dépend des distributions, une partie seulement dépend des données.\n",
    "\n",
    "$$ -(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)) = -\\frac{1}{2} ( x^T\\Sigma_i^{-1}x + \\mu_i^T\\Sigma_i^{-1}\\mu_i - x^T\\Sigma_i^{-1}\\mu_i - \\mu_i^T\\Sigma_i^{-1}x ) $$ \n",
    "\n",
    "Calculez chacun de ces termes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cade4",
   "metadata": {},
   "source": [
    "Analyse du terme independant des données:\n",
    "\n",
    "$$ \\mu_i^T\\Sigma_i^{-1}\\mu_i $$\n",
    "\n",
    "$$ \\mu_i^T$$ est de dimension (1, 39) $$\\Sigma_i$$ est de dimension (39, 39)\n",
    "\n",
    "Donc $$ \\mu_i^T\\Sigma_i^{-1}\\mu_i $$ est de dimension (1,)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9756cb23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T06:06:11.538097Z",
     "start_time": "2024-09-12T06:06:11.529402Z"
    }
   },
   "source": [
    "# En pratique, comme la matruice de covariance est diagonale, nous n'avons pas besoin de calculer un vrai produit matriciel\n",
    "# Écrivez la valeur du premier terme de \\mu_i \\Sigma^{-1}_i et tirez partie de cette expression pour simplifier\n",
    "# le calcul de ce terme\n",
    "\n",
    "# self.mu est de dimension 64x39\n",
    "# self.invcov est de dimension 64x39\n",
    "# numpy.square(self.mu) * self.invcov) est de dimension 64x39\n",
    "# numpy.square(self.mu) * self.invcov).sum(1) est de dimension 64 \n",
    "# A est de dimension 64\n",
    "\n",
    "a_idpt = numpy.sum( numpy.square(mixture.mu) * mixture.invcov, axis=1 )\n",
    "print(a_idpt, a_idpt.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.06258507 34.9974304  25.07955728 24.4477801  29.30450087 23.53093618\n",
      " 17.97478978 27.49854067 33.14749497 24.18498924 21.74967277 20.35285252\n",
      " 23.32292406 39.97481249 32.31881181 25.03008533 20.10366642 32.42881905\n",
      " 32.56320818 24.59221355 20.88498159 24.38585148 16.69366773 35.32670674\n",
      " 14.82171863 30.3776522  42.53213539 40.03429768 28.0882865  30.53235822\n",
      " 24.96461008 29.58541189 37.57946244 28.75486441 24.63392124 28.06858742\n",
      " 39.07440781 39.92516607 22.50515188 22.14158314 25.76064448 28.13461136\n",
      " 20.41493897 19.16378518 34.64329639 19.50864393 33.01843831 29.65358247\n",
      " 17.39356694 29.01589355 31.18336031 28.7124705  24.41168099 24.92588735\n",
      " 19.18626158 29.05813811 30.12623722 29.41842831 33.84483729 30.3030583\n",
      " 40.39943314 27.4758611  29.12646595 26.39505375] (64,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pareil pour le terme $$ x^T\\Sigma_i^{-1}x = \\sum_{n=1}^{39}{x^2 \\sigma_n} $$",
   "id": "9f2006403365e1ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T06:06:16.259653Z",
     "start_time": "2024-09-12T06:06:16.084569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = numpy.load(\"features/features_0.npy\")\n",
    "\n",
    "def f(x):\n",
    "    return numpy.sum( numpy.square(x) * mixture.invcov, axis=1 )\n",
    "\n",
    "b_x2 = []\n",
    "\n",
    "for x in X:\n",
    "    b_x2.append(f(x))\n",
    "    \n",
    "b_x2 = numpy.array(b_x2)\n",
    "print(b_x2, b_x2.shape)"
   ],
   "id": "d40a6e4564dcd392",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.31230817 35.57492947 38.99114351 ... 34.15860092 39.43752767\n",
      "  30.8941242 ]\n",
      " [51.15131914 60.61843294 62.29082171 ... 56.49160923 66.87870798\n",
      "  53.06242306]\n",
      " [70.83919397 83.36414292 87.95483019 ... 80.93612559 91.63412588\n",
      "  70.79893953]\n",
      " ...\n",
      " [49.78288519 58.71514122 62.6343546  ... 58.57760071 61.74498848\n",
      "  51.66981218]\n",
      " [43.27393968 51.37402635 56.18306032 ... 54.05507456 54.49923773\n",
      "  46.33599516]\n",
      " [56.29844509 61.20991474 64.47810812 ... 58.69314188 64.52144284\n",
      "  51.81331524]] (3288, 64)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "$$ - x^T\\Sigma_i^{-1}\\mu_i - \\mu_i^T\\Sigma_i^{-1}x = 2 \\cdot \\sum_{n=1}^{39}{x \\sigma_n \\mu_n} $$ ",
   "id": "139e2b6127a6ee45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T06:06:18.683088Z",
     "start_time": "2024-09-12T06:06:18.538606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def g(x):\n",
    "    return ( numpy.sum(x * mixture.invcov * mixture.mu, axis=1) )\n",
    "\n",
    "c_musigmax = []\n",
    "\n",
    "for x in X:\n",
    "    c_musigmax.append(g(x))\n",
    "    \n",
    "c_musigmax = numpy.array(c_musigmax)\n",
    "print(c_musigmax, c_musigmax.shape)"
   ],
   "id": "e0aced5bcea54c3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.58801514  -5.96381771  -4.83292118 ...  -0.79741204  -3.76346581\n",
      "   -5.35207078]\n",
      " [ -2.53498114 -13.52977725  -4.09763207 ...  11.81686344  12.40727693\n",
      "   -8.18419267]\n",
      " [  7.57194635  16.00643795   4.36083431 ...   0.91937211   9.4549122\n",
      "    3.3095916 ]\n",
      " ...\n",
      " [ -5.45560549   4.39783807  26.79397798 ...  10.33471163   5.1771689\n",
      "    6.51704925]\n",
      " [ -3.02075171  10.48196304   3.28941427 ...  -2.26414699  -0.61125185\n",
      "   -5.1614433 ]\n",
      " [ -2.543049     4.34422535   5.75279854 ...  -2.24565835  14.18855217\n",
      "   -1.76493032]] (3288, 64)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T06:06:22.127580Z",
     "start_time": "2024-09-12T06:06:22.113111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "exp = - ( a_idpt + b_x2 - 2.0 * c_musigmax ) / 2.0\n",
    "print(exp, exp.shape)"
   ],
   "id": "a706b5b048b99bc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-33.77546176 -41.24999765 -36.86827158 ... -31.61464305 -38.04546262\n",
      "  -33.99665976]\n",
      " [-43.64193324 -61.33770892 -47.78282157 ... -30.16687173 -35.59531004\n",
      "  -47.91293108]\n",
      " [-43.37894317 -43.17434871 -52.15635943 ... -53.28662124 -50.92538372\n",
      "  -45.28740504]\n",
      " ...\n",
      " [-45.87834062 -42.45844774 -17.06297797 ... -32.69201927 -40.25855832\n",
      "  -32.51538372]\n",
      " [-40.18901408 -32.70376534 -37.34189453 ... -43.02961482 -42.4241037\n",
      "  -41.52696775]\n",
      " [-46.22356408 -43.75944722 -39.02603416 ... -45.33015984 -32.63540222\n",
      "  -40.86911482]] (3288, 64)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "a738780d-c5ce-4136-a2e3-9a9911029daa",
   "metadata": {},
   "source": [
    "## 1.2) Écrivez une fonction compute_lpp \n",
    "\n",
    "Cette méthode de la class **Mixture** va calculer les log posterior probabilités $$\\log{p_i(x)}$$ d'un ensemble de vecteurs sur ce mélange de Gaussienne à matrices de covariances diagonales\n",
    "\n",
    "Pour acumuler les statistiques, vous allez créer un objet mixture que vous appelerez **accum**.\n",
    "\n",
    "* Cette méthode prend en paramètres une matrice de coefficients cepstraux de dimension N x F où N est le nombre de vecteurs (variable selon les fichiers) et F est la dimension des vecteurs (39 dans notre cas)\n",
    "* En premier lieu, pensez à extraire des boucles tous les termes qui ne dépendent pas des données\n",
    "* Cette méthode renvoie les $$n_i$$ (donc un vecteur)\n",
    "\n",
    "Pour rappel: \n",
    "$$p_i(x) = \\frac{1}{(2\\pi)^{\\frac{D}{2}}|\\Sigma_i|^\\frac{1}{2}} e^{-(\\frac{1}{2}(x - \\mu)^T\\Sigma_i^{-1}(x-\\mu))}$$\n",
    "sachant:\n",
    "$$ -(\\frac{1}{2}(x - \\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)) = -\\frac{1}{2} ( x^T\\Sigma_i^{-1}x + \\mu_i^T\\Sigma_i^{-1}\\mu_i - x^T\\Sigma_i^{-1}\\mu_i - \\mu_i^T\\Sigma_i^{-1}x ) $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73558128-8817-4016-aa2d-f8559ad436ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "X = numpy.load(\"features_1.npy\")\n",
    "\n",
    "def compute_lpp(X):\n",
    "    log_pi = numpy.log(mixture.cst)\n",
    "    \n",
    "    # Calcul de la partie indépendante des données:\n",
    "    a_idpt = numpy.sum( numpy.square(mixture.mu) * mixture.invcov, axis=1 )\n",
    "    \n",
    "    # Calcul des parties dépendantes des données:\n",
    "    b_x2 = []\n",
    "    for x in X:\n",
    "        b_x2.append(numpy.sum( numpy.square(x) * mixture.invcov, axis=1 ))\n",
    "    b_x2 = numpy.array(b_x2)\n",
    "    \n",
    "    c_musigmax = []\n",
    "    for x in X:\n",
    "        c_musigmax.append(numpy.sum(x * mixture.invcov * mixture.mu, axis=1))\n",
    "    c_musigmax = numpy.array(c_musigmax)\n",
    "    \n",
    "    exp = - ( a_idpt + b_x2 - 2.0 * c_musigmax ) / 2.0\n",
    "    \n",
    "    log_pi += exp\n",
    "    \n",
    "    return log_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61a954-76a6-4ecf-b6b1-61ee35c4d235",
   "metadata": {},
   "source": [
    "## 1.3) Utilisez la fonction **sum_log_probabilities**\n",
    "* Que fait cette fonction qui vous est donnée?\n",
    "* Pourquoi l'utilise-t'on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b29bd63-76a6-4290-81b2-f6ae7f73693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_log_probabilities(lp):\n",
    "    \"\"\"Sum log probabilities in a secure manner to avoid extreme values\n",
    "\n",
    "    :param lp: numpy array of log-probabilities to sum\n",
    "    \"\"\"\n",
    "    pp_max = numpy.max(lp, axis=1)\n",
    "    log_lk = pp_max + numpy.log(numpy.sum(numpy.exp((lp.transpose() - pp_max).T), axis=1))\n",
    "    ind = ~numpy.isfinite(pp_max)\n",
    "    if sum(ind) != 0:\n",
    "        log_lk[ind] = pp_max[ind]\n",
    "    pp = numpy.exp((lp.transpose() - log_lk).transpose())\n",
    "    llk = log_lk.sum()\n",
    "    return pp, llk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1ee10-f7d7-4be1-9e0a-762be74bb52d",
   "metadata": {},
   "source": [
    "## 1.4) Bouclez sur les fichiers de paramètres pour accumuler les statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c44723-f60f-4371-b18d-6f2d4c98dbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
